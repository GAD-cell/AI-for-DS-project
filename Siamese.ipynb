{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972611e9",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9866ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca7be2",
   "metadata": {},
   "source": [
    "### Some utils for images and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c5d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, text=None, should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(\n",
    "            75,\n",
    "            8,\n",
    "            text,\n",
    "            style=\"italic\",\n",
    "            fontweight=\"bold\",\n",
    "            bbox={\"facecolor\": \"white\", \"alpha\": 0.8, \"pad\": 10},\n",
    "        )\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_plot(iteration, loss):\n",
    "    plt.plot(iteration, loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23eafbe",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0137004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_dir = \"UTsig\"\n",
    "training_csv = \"train.csv\"\n",
    "testing_csv = \"test.csv\"\n",
    "#testing_dir = \"UTsig\"\n",
    "batch_size = 8\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f29b56",
   "metadata": {},
   "source": [
    "### Contrastive loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48dac1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"Contrastive loss function\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean(\n",
    "            (1 - label) * torch.pow(euclidean_distance, 2)\n",
    "            + (label)\n",
    "            * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        )\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b38365",
   "metadata": {},
   "source": [
    "### Preprocessing and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2dbcdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataset:\n",
    "    def __init__(self, training_csv=None, \n",
    "                 #training_dir=None, \n",
    "                 transform=None):\n",
    "        # used to prepare the labels and images path\n",
    "        self.train_df = pd.read_csv(training_csv)\n",
    "        self.train_df=self.train_df[:1000]\n",
    "        #self.train_df.columns = [\"image1\", \"image2\", \"label\"]\n",
    "        #self.train_dir = training_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # getting the image path\n",
    "        #image1_path = os.path.join(self.train_dir, self.train_df.iat[index, 0])\n",
    "        #image2_path = os.path.join(self.train_dir, self.train_df.iat[index, 1])\n",
    "        image1_path = self.train_df.iat[index, 0]\n",
    "        image2_path = self.train_df.iat[index, 1]\n",
    "\n",
    "        # Loading the image\n",
    "        img0 = Image.open(image1_path)\n",
    "        img1 = Image.open(image2_path)\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "\n",
    "        # Apply image transformations\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "\n",
    "        return (\n",
    "            img0,\n",
    "            img1,\n",
    "            torch.from_numpy(\n",
    "                np.array([int(self.train_df.iat[index, 2])], dtype=np.float32)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be234b",
   "metadata": {},
   "source": [
    "### Load the the dataset from raw image folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d69489",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_dataset = SiameseDataset(\n",
    "    training_csv,\n",
    "    #training_dir,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((105, 105)), transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "\n",
    "eval_dataset = SiameseDataset(\n",
    "    testing_csv,\n",
    "    #training_dir,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((105, 105)), transforms.ToTensor()]\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3409890",
   "metadata": {},
   "source": [
    "### Viewing the sample of images and to check whether its loading properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80c69c1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './UTSig/Genuine/45/13.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6215f2535cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexample_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mconcatenated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcatenated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4e15316da88b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Loading the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mimg0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage1_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage2_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mimg0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './UTSig/Genuine/45/13.png'"
     ]
    }
   ],
   "source": [
    "vis_dataloader = DataLoader(siamese_dataset, shuffle=True, batch_size=8)\n",
    "dataiter = iter(vis_dataloader)\n",
    "\n",
    "\n",
    "example_batch = next(dataiter)\n",
    "concatenated = torch.cat((example_batch[0], example_batch[1]), 0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(example_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0cff11",
   "metadata": {},
   "source": [
    "### Create a siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "771df697",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
    "            nn.BatchNorm2d(96),\n",
    "            #nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "\n",
    "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Defining the fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(30976, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(128,2))\n",
    "        \n",
    "  \n",
    "  \n",
    "    def forward_once(self, x):\n",
    "        # Forward pass \n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # forward pass of input 1\n",
    "        output1 = self.forward_once(input1)\n",
    "        # forward pass of input 2\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a542ef",
   "metadata": {},
   "source": [
    "### Load the dataset as pytorch tensors using dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0,\n",
    "                        batch_size=batch_size) \n",
    "eval_dataloader = DataLoader(eval_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0,\n",
    "                        batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9ab5a7",
   "metadata": {},
   "source": [
    "### Declare Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df202248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 256, 11, 11]         --\n",
      "|    └─Conv2d: 2-1                       [-1, 96, 95, 95]          11,712\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 96, 95, 95]          192\n",
      "|    └─ReLU: 2-3                         [-1, 96, 95, 95]          --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 96, 47, 47]          --\n",
      "|    └─Conv2d: 2-5                       [-1, 256, 47, 47]         614,656\n",
      "|    └─BatchNorm2d: 2-6                  [-1, 256, 47, 47]         512\n",
      "|    └─ReLU: 2-7                         [-1, 256, 47, 47]         --\n",
      "|    └─MaxPool2d: 2-8                    [-1, 256, 23, 23]         --\n",
      "|    └─Dropout2d: 2-9                    [-1, 256, 23, 23]         --\n",
      "|    └─Conv2d: 2-10                      [-1, 384, 23, 23]         885,120\n",
      "|    └─BatchNorm2d: 2-11                 [-1, 384, 23, 23]         768\n",
      "|    └─ReLU: 2-12                        [-1, 384, 23, 23]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 256, 23, 23]         884,992\n",
      "|    └─BatchNorm2d: 2-14                 [-1, 256, 23, 23]         512\n",
      "|    └─ReLU: 2-15                        [-1, 256, 23, 23]         --\n",
      "|    └─MaxPool2d: 2-16                   [-1, 256, 11, 11]         --\n",
      "|    └─Dropout2d: 2-17                   [-1, 256, 11, 11]         --\n",
      "├─Sequential: 1-2                        [-1, 2]                   --\n",
      "|    └─Linear: 2-18                      [-1, 1024]                31,720,448\n",
      "|    └─ReLU: 2-19                        [-1, 1024]                --\n",
      "|    └─Dropout2d: 2-20                   [-1, 1024]                --\n",
      "|    └─Linear: 2-21                      [-1, 128]                 131,200\n",
      "|    └─ReLU: 2-22                        [-1, 128]                 --\n",
      "|    └─Linear: 2-23                      [-1, 2]                   258\n",
      "├─Sequential: 1-3                        [-1, 256, 11, 11]         (recursive)\n",
      "|    └─Conv2d: 2-24                      [-1, 96, 95, 95]          (recursive)\n",
      "|    └─BatchNorm2d: 2-25                 [-1, 96, 95, 95]          (recursive)\n",
      "|    └─ReLU: 2-26                        [-1, 96, 95, 95]          --\n",
      "|    └─MaxPool2d: 2-27                   [-1, 96, 47, 47]          --\n",
      "|    └─Conv2d: 2-28                      [-1, 256, 47, 47]         (recursive)\n",
      "|    └─BatchNorm2d: 2-29                 [-1, 256, 47, 47]         (recursive)\n",
      "|    └─ReLU: 2-30                        [-1, 256, 47, 47]         --\n",
      "|    └─MaxPool2d: 2-31                   [-1, 256, 23, 23]         --\n",
      "|    └─Dropout2d: 2-32                   [-1, 256, 23, 23]         --\n",
      "|    └─Conv2d: 2-33                      [-1, 384, 23, 23]         (recursive)\n",
      "|    └─BatchNorm2d: 2-34                 [-1, 384, 23, 23]         (recursive)\n",
      "|    └─ReLU: 2-35                        [-1, 384, 23, 23]         --\n",
      "|    └─Conv2d: 2-36                      [-1, 256, 23, 23]         (recursive)\n",
      "|    └─BatchNorm2d: 2-37                 [-1, 256, 23, 23]         (recursive)\n",
      "|    └─ReLU: 2-38                        [-1, 256, 23, 23]         --\n",
      "|    └─MaxPool2d: 2-39                   [-1, 256, 11, 11]         --\n",
      "|    └─Dropout2d: 2-40                   [-1, 256, 11, 11]         --\n",
      "├─Sequential: 1-4                        [-1, 2]                   (recursive)\n",
      "|    └─Linear: 2-41                      [-1, 1024]                (recursive)\n",
      "|    └─ReLU: 2-42                        [-1, 1024]                --\n",
      "|    └─Dropout2d: 2-43                   [-1, 1024]                --\n",
      "|    └─Linear: 2-44                      [-1, 128]                 (recursive)\n",
      "|    └─ReLU: 2-45                        [-1, 128]                 --\n",
      "|    └─Linear: 2-46                      [-1, 2]                   (recursive)\n",
      "==========================================================================================\n",
      "Total params: 34,250,370\n",
      "Trainable params: 34,250,370\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 4.93\n",
      "==========================================================================================\n",
      "Input size (MB): 0.08\n",
      "Forward/backward pass size (MB): 27.02\n",
      "Params size (MB): 130.65\n",
      "Estimated Total Size (MB): 157.76\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 256, 11, 11]         --\n",
       "|    └─Conv2d: 2-1                       [-1, 96, 95, 95]          11,712\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 96, 95, 95]          192\n",
       "|    └─ReLU: 2-3                         [-1, 96, 95, 95]          --\n",
       "|    └─MaxPool2d: 2-4                    [-1, 96, 47, 47]          --\n",
       "|    └─Conv2d: 2-5                       [-1, 256, 47, 47]         614,656\n",
       "|    └─BatchNorm2d: 2-6                  [-1, 256, 47, 47]         512\n",
       "|    └─ReLU: 2-7                         [-1, 256, 47, 47]         --\n",
       "|    └─MaxPool2d: 2-8                    [-1, 256, 23, 23]         --\n",
       "|    └─Dropout2d: 2-9                    [-1, 256, 23, 23]         --\n",
       "|    └─Conv2d: 2-10                      [-1, 384, 23, 23]         885,120\n",
       "|    └─BatchNorm2d: 2-11                 [-1, 384, 23, 23]         768\n",
       "|    └─ReLU: 2-12                        [-1, 384, 23, 23]         --\n",
       "|    └─Conv2d: 2-13                      [-1, 256, 23, 23]         884,992\n",
       "|    └─BatchNorm2d: 2-14                 [-1, 256, 23, 23]         512\n",
       "|    └─ReLU: 2-15                        [-1, 256, 23, 23]         --\n",
       "|    └─MaxPool2d: 2-16                   [-1, 256, 11, 11]         --\n",
       "|    └─Dropout2d: 2-17                   [-1, 256, 11, 11]         --\n",
       "├─Sequential: 1-2                        [-1, 2]                   --\n",
       "|    └─Linear: 2-18                      [-1, 1024]                31,720,448\n",
       "|    └─ReLU: 2-19                        [-1, 1024]                --\n",
       "|    └─Dropout2d: 2-20                   [-1, 1024]                --\n",
       "|    └─Linear: 2-21                      [-1, 128]                 131,200\n",
       "|    └─ReLU: 2-22                        [-1, 128]                 --\n",
       "|    └─Linear: 2-23                      [-1, 2]                   258\n",
       "├─Sequential: 1-3                        [-1, 256, 11, 11]         (recursive)\n",
       "|    └─Conv2d: 2-24                      [-1, 96, 95, 95]          (recursive)\n",
       "|    └─BatchNorm2d: 2-25                 [-1, 96, 95, 95]          (recursive)\n",
       "|    └─ReLU: 2-26                        [-1, 96, 95, 95]          --\n",
       "|    └─MaxPool2d: 2-27                   [-1, 96, 47, 47]          --\n",
       "|    └─Conv2d: 2-28                      [-1, 256, 47, 47]         (recursive)\n",
       "|    └─BatchNorm2d: 2-29                 [-1, 256, 47, 47]         (recursive)\n",
       "|    └─ReLU: 2-30                        [-1, 256, 47, 47]         --\n",
       "|    └─MaxPool2d: 2-31                   [-1, 256, 23, 23]         --\n",
       "|    └─Dropout2d: 2-32                   [-1, 256, 23, 23]         --\n",
       "|    └─Conv2d: 2-33                      [-1, 384, 23, 23]         (recursive)\n",
       "|    └─BatchNorm2d: 2-34                 [-1, 384, 23, 23]         (recursive)\n",
       "|    └─ReLU: 2-35                        [-1, 384, 23, 23]         --\n",
       "|    └─Conv2d: 2-36                      [-1, 256, 23, 23]         (recursive)\n",
       "|    └─BatchNorm2d: 2-37                 [-1, 256, 23, 23]         (recursive)\n",
       "|    └─ReLU: 2-38                        [-1, 256, 23, 23]         --\n",
       "|    └─MaxPool2d: 2-39                   [-1, 256, 11, 11]         --\n",
       "|    └─Dropout2d: 2-40                   [-1, 256, 11, 11]         --\n",
       "├─Sequential: 1-4                        [-1, 2]                   (recursive)\n",
       "|    └─Linear: 2-41                      [-1, 1024]                (recursive)\n",
       "|    └─ReLU: 2-42                        [-1, 1024]                --\n",
       "|    └─Dropout2d: 2-43                   [-1, 1024]                --\n",
       "|    └─Linear: 2-44                      [-1, 128]                 (recursive)\n",
       "|    └─ReLU: 2-45                        [-1, 128]                 --\n",
       "|    └─Linear: 2-46                      [-1, 2]                   (recursive)\n",
       "==========================================================================================\n",
       "Total params: 34,250,370\n",
       "Trainable params: 34,250,370\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.93\n",
       "==========================================================================================\n",
       "Input size (MB): 0.08\n",
       "Forward/backward pass size (MB): 27.02\n",
       "Params size (MB): 130.65\n",
       "Estimated Total Size (MB): 157.76\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = SiameseNetwork()\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(net,[(1, 105, 105),(1, 105, 105)])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de6600",
   "metadata": {},
   "source": [
    "### Decalre Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23cb198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ContrastiveLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c42b3f",
   "metadata": {},
   "source": [
    "### Declare Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "856cb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d014231",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039dc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GAD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.039051703002929684\n",
      "--------------------\n",
      "Eval loss0.010450723861694336\n",
      "--------------------\n",
      "Best Eval loss0.010450723861694336\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010606551643371582\n",
      "--------------------\n",
      "Eval loss0.010678295116424562\n",
      "--------------------\n",
      "Best Eval loss0.010678295116424562\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010491210792541504\n",
      "--------------------\n",
      "Eval loss0.011128221927642823\n",
      "--------------------\n",
      "Best Eval loss0.011128221927642823\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.01047040644454956\n",
      "--------------------\n",
      "Eval loss0.010407899566650392\n",
      "--------------------\n",
      "Best Eval loss0.010407899566650392\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010298498043060302\n",
      "--------------------\n",
      "Eval loss0.01027693793106079\n",
      "--------------------\n",
      "Best Eval loss0.01027693793106079\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010299983074188232\n",
      "--------------------\n",
      "Eval loss0.012066418834686279\n",
      "--------------------\n",
      "Best Eval loss0.012066418834686279\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010644933868408204\n",
      "--------------------\n",
      "Eval loss0.013089199462890624\n",
      "--------------------\n",
      "Best Eval loss0.013089199462890624\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010789308757781984\n",
      "--------------------\n",
      "Eval loss0.010027235744476318\n",
      "--------------------\n",
      "Best Eval loss0.010027235744476318\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010233500644683839\n",
      "--------------------\n",
      "Eval loss0.010649137084960937\n",
      "--------------------\n",
      "Best Eval loss0.010649137084960937\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010158987491607666\n",
      "--------------------\n",
      "Eval loss0.010533370342254638\n",
      "--------------------\n",
      "Best Eval loss0.010533370342254638\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.01048699600982666\n",
      "--------------------\n",
      "Eval loss0.010343980724334716\n",
      "--------------------\n",
      "Best Eval loss0.010343980724334716\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010640215129852295\n",
      "--------------------\n",
      "Eval loss0.013028033460617065\n",
      "--------------------\n",
      "Best Eval loss0.013028033460617065\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010946937015533446\n",
      "--------------------\n",
      "Eval loss0.010916289524078368\n",
      "--------------------\n",
      "Best Eval loss0.010916289524078368\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010603044605255126\n",
      "--------------------\n",
      "Eval loss0.011028649253845215\n",
      "--------------------\n",
      "Best Eval loss0.011028649253845215\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010552309211730957\n",
      "--------------------\n",
      "Eval loss0.010220768718719481\n",
      "--------------------\n",
      "Best Eval loss0.010220768718719481\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010734397186279297\n",
      "--------------------\n",
      "Eval loss0.01105551459121704\n",
      "--------------------\n",
      "Best Eval loss0.01105551459121704\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010368147048950196\n",
      "--------------------\n",
      "Eval loss0.00974878761291504\n",
      "--------------------\n",
      "Best Eval loss0.00974878761291504\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010820335414886476\n",
      "--------------------\n",
      "Eval loss0.010680179191589355\n",
      "--------------------\n",
      "Best Eval loss0.010680179191589355\n",
      "Model Saved Successfully\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "batch 10\n",
      "batch 11\n",
      "batch 12\n",
      "batch 13\n",
      "batch 14\n",
      "batch 15\n",
      "batch 16\n",
      "batch 17\n",
      "batch 18\n",
      "batch 19\n",
      "batch 20\n",
      "batch 21\n",
      "batch 22\n",
      "batch 23\n",
      "batch 24\n",
      "batch 25\n",
      "batch 26\n",
      "batch 27\n",
      "batch 28\n",
      "batch 29\n",
      "batch 30\n",
      "batch 31\n",
      "batch 32\n",
      "batch 33\n",
      "batch 34\n",
      "batch 35\n",
      "batch 36\n",
      "batch 37\n",
      "batch 38\n",
      "batch 39\n",
      "batch 40\n",
      "batch 41\n",
      "batch 42\n",
      "batch 43\n",
      "batch 44\n",
      "batch 45\n",
      "batch 46\n",
      "batch 47\n",
      "batch 48\n",
      "batch 49\n",
      "batch 50\n",
      "batch 51\n",
      "batch 52\n",
      "batch 53\n",
      "batch 54\n",
      "batch 55\n",
      "batch 56\n",
      "batch 57\n",
      "batch 58\n",
      "batch 59\n",
      "batch 60\n",
      "batch 61\n",
      "batch 62\n",
      "batch 63\n",
      "batch 64\n",
      "batch 65\n",
      "batch 66\n",
      "batch 67\n",
      "batch 68\n",
      "batch 69\n",
      "batch 70\n",
      "batch 71\n",
      "batch 72\n",
      "batch 73\n",
      "batch 74\n",
      "batch 75\n",
      "batch 76\n",
      "batch 77\n",
      "batch 78\n",
      "batch 79\n",
      "batch 80\n",
      "batch 81\n",
      "batch 82\n",
      "batch 83\n",
      "batch 84\n",
      "batch 85\n",
      "batch 86\n",
      "batch 87\n",
      "batch 88\n",
      "batch 89\n",
      "batch 90\n",
      "batch 91\n",
      "batch 92\n",
      "batch 93\n",
      "batch 94\n",
      "batch 95\n",
      "batch 96\n",
      "batch 97\n",
      "batch 98\n",
      "batch 99\n",
      "batch 100\n",
      "batch 101\n",
      "batch 102\n",
      "batch 103\n",
      "batch 104\n",
      "batch 105\n",
      "batch 106\n",
      "batch 107\n",
      "batch 108\n",
      "batch 109\n",
      "batch 110\n",
      "batch 111\n",
      "batch 112\n",
      "batch 113\n",
      "batch 114\n",
      "batch 115\n",
      "batch 116\n",
      "batch 117\n",
      "batch 118\n",
      "batch 119\n",
      "batch 120\n",
      "batch 121\n",
      "batch 122\n",
      "batch 123\n",
      "batch 124\n",
      "Training loss0.010957152824401855\n",
      "--------------------\n",
      "Eval loss0.010225070552825928\n",
      "--------------------\n",
      "Best Eval loss0.010225070552825928\n",
      "Model Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "def train(train_dataloader):\n",
    "    loss=[] \n",
    "    counter=[]\n",
    "    iteration_number = 0\n",
    "    for i, data in enumerate(train_dataloader,0):\n",
    "      print(f\"batch {i}\")\n",
    "      img0, img1 , label = data\n",
    "      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "      optimizer.zero_grad()\n",
    "      output1,output2 = net(img0,img1)\n",
    "      loss_contrastive = criterion(output1,output2,label)\n",
    "      loss_contrastive.backward()\n",
    "      optimizer.step()\n",
    "      loss.append(loss_contrastive.item())\n",
    "    loss = np.array(loss)\n",
    "    return loss.mean()/len(train_dataloader)\n",
    "\n",
    "\n",
    "def eval(eval_dataloader):\n",
    "    loss=[] \n",
    "    counter=[]\n",
    "    iteration_number = 0\n",
    "    for i, data in enumerate(eval_dataloader,0):\n",
    "      img0, img1 , label = data\n",
    "      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "      output1,output2 = net(img0,img1)\n",
    "      loss_contrastive = criterion(output1,output2,label)\n",
    "      loss.append(loss_contrastive.item())\n",
    "    loss = np.array(loss)\n",
    "    return loss.mean()/len(eval_dataloader)\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "  best_eval_loss = 9999\n",
    "  train_loss = train(train_dataloader)\n",
    "  eval_loss = eval(eval_dataloader)\n",
    "\n",
    "  print(f\"Training loss{train_loss}\")\n",
    "  print(\"-\"*20)\n",
    "  print(f\"Eval loss{eval_loss}\")\n",
    "\n",
    "  if eval_loss<best_eval_loss:\n",
    "    best_eval_loss = eval_loss\n",
    "    print(\"-\"*20)\n",
    "    print(f\"Best Eval loss{best_eval_loss}\")\n",
    "    torch.save(net.state_dict(), \"./content/model.pth\")\n",
    "    print(\"Model Saved Successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf720f",
   "metadata": {},
   "source": [
    "### Performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9697198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Siamese network on the test set: 63.10%\n"
     ]
    }
   ],
   "source": [
    "model_path = './content/model.pth'\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "net.eval()  # Set the model to evaluation mode\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "threshold=0.01\n",
    "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "    for i, data in enumerate(eval_dataloader,0):\n",
    "        img0, img1 , label = data\n",
    "        img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "        output1,output2 = net(img0,img1)\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        predicted = (euclidean_distance > threshold).float()\n",
    "        predicted=predicted.reshape(-1,1)\n",
    "        total += label.size(0)\n",
    "        correct += torch.sum(predicted == label)\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the Siamese network on the test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77f8d2a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ed54dbe52574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Evaluate the model on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mimg0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mimg0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import det_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store true labels and predicted scores\n",
    "true_labels = []\n",
    "predicted_scores = []\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "with torch.no_grad():  \n",
    "    for i, data in enumerate(eval_dataloader, 0):\n",
    "        img0, img1, label = data\n",
    "        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "        \n",
    "        # Forward pass\n",
    "        output1, output2 = net(img0, img1)\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        predicted_scores.extend(euclidean_distance.cpu().numpy())\n",
    "        true_labels.extend(label.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_scores = np.array(predicted_scores)\n",
    "\n",
    "# Compute ROC curve and ROC area\n",
    "far, frr, thresholds = det_curve(true_labels, predicted_scores, pos_label=0)\n",
    "roc_auc = auc(far, frr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(far, frr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Acceptance Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Print AUC score\n",
    "print(f'AUC: {roc_auc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66514cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
