{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972611e9",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9866ceb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anton.orlovskiy\\AppData\\Local\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca7be2",
   "metadata": {},
   "source": [
    "### Some utils for images and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c5d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, text=None, should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(\n",
    "            75,\n",
    "            8,\n",
    "            text,\n",
    "            style=\"italic\",\n",
    "            fontweight=\"bold\",\n",
    "            bbox={\"facecolor\": \"white\", \"alpha\": 0.8, \"pad\": 10},\n",
    "        )\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_plot(iteration, loss):\n",
    "    plt.plot(iteration, loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23eafbe",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0137004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_dir = \"UTsig\"\n",
    "training_csv = \"train.csv\"\n",
    "testing_csv = \"test.csv\"\n",
    "#testing_dir = \"UTsig\"\n",
    "batch_size = 32\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f29b56",
   "metadata": {},
   "source": [
    "### Contrastive loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48dac1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"Contrastive loss function\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean(\n",
    "            (1 - label) * torch.pow(euclidean_distance, 2)\n",
    "            + (label)\n",
    "            * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        )\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b38365",
   "metadata": {},
   "source": [
    "### Preprocessing and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2dbcdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataset:\n",
    "    def __init__(self, training_csv=None, \n",
    "                 #training_dir=None, \n",
    "                 transform=None):\n",
    "        # used to prepare the labels and images path\n",
    "        self.train_df = pd.read_csv(training_csv)\n",
    "        #self.train_df.columns = [\"image1\", \"image2\", \"label\"]\n",
    "        #self.train_dir = training_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # getting the image path\n",
    "        #image1_path = os.path.join(self.train_dir, self.train_df.iat[index, 0])\n",
    "        #image2_path = os.path.join(self.train_dir, self.train_df.iat[index, 1])\n",
    "        image1_path = self.train_df.iat[index, 0]\n",
    "        image2_path = self.train_df.iat[index, 1]\n",
    "\n",
    "        # Loading the image\n",
    "        img0 = Image.open(image1_path)\n",
    "        img1 = Image.open(image2_path)\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "\n",
    "        # Apply image transformations\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "\n",
    "        return (\n",
    "            img0,\n",
    "            img1,\n",
    "            torch.from_numpy(\n",
    "                np.array([int(self.train_df.iat[index, 2])], dtype=np.float32)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be234b",
   "metadata": {},
   "source": [
    "### Load the the dataset from raw image folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d69489",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_dataset = SiameseDataset(\n",
    "    training_csv,\n",
    "    #training_dir,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((105, 105)), transforms.ToTensor()]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3409890",
   "metadata": {},
   "source": [
    "### Viewing the sample of images and to check whether its loading properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c69c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_dataloader = DataLoader(siamese_dataset, shuffle=True, batch_size=8)\n",
    "dataiter = iter(vis_dataloader)\n",
    "\n",
    "\n",
    "example_batch = next(dataiter)\n",
    "concatenated = torch.cat((example_batch[0], example_batch[1]), 0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(example_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0cff11",
   "metadata": {},
   "source": [
    "### Create a siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771df697",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
    "            nn.BatchNorm2d(96),\n",
    "            #nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "\n",
    "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Defining the fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(30976, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(128,2))\n",
    "        \n",
    "  \n",
    "  \n",
    "    def forward_once(self, x):\n",
    "        # Forward pass \n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # forward pass of input 1\n",
    "        output1 = self.forward_once(input1)\n",
    "        # forward pass of input 2\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a542ef",
   "metadata": {},
   "source": [
    "### Load the dataset as pytorch tensors using dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        batch_size=config.batch_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9ab5a7",
   "metadata": {},
   "source": [
    "### Declare Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df202248",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNetwork().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de6600",
   "metadata": {},
   "source": [
    "### Decalre Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ContrastiveLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c42b3f",
   "metadata": {},
   "source": [
    "### Declare Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856cb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d014231",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader):\n",
    "    loss=[] \n",
    "    counter=[]\n",
    "    iteration_number = 0\n",
    "    for i, data in enumerate(train_dataloader,0):\n",
    "      img0, img1 , label = data\n",
    "      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "      optimizer.zero_grad()\n",
    "      output1,output2 = net(img0,img1)\n",
    "      loss_contrastive = criterion(output1,output2,label)\n",
    "      loss_contrastive.backward()\n",
    "      optimizer.step()\n",
    "      loss.append(loss_contrastive.item())\n",
    "    loss = np.array(loss)\n",
    "    return loss.mean()/len(train_dataloader)\n",
    "\n",
    "\n",
    "def eval(eval_dataloader):\n",
    "    loss=[] \n",
    "    counter=[]\n",
    "    iteration_number = 0\n",
    "    for i, data in enumerate(eval_dataloader,0):\n",
    "      img0, img1 , label = data\n",
    "      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "      output1,output2 = net(img0,img1)\n",
    "      loss_contrastive = criterion(output1,output2,label)\n",
    "      loss.append(loss_contrastive.item())\n",
    "    loss = np.array(loss)\n",
    "    return loss.mean()/len(eval_dataloader)\n",
    "\n",
    "\n",
    "for epoch in range(1,config.epochs):\n",
    "  best_eval_loss = 9999\n",
    "  train_loss = train(train_dataloader)\n",
    "  eval_loss = eval(eval_dataloader)\n",
    "\n",
    "  print(f\"Training loss{train_loss}\")\n",
    "  print(\"-\"*20)\n",
    "  print(f\"Eval loss{eval_loss}\")\n",
    "\n",
    "  if eval_loss<best_eval_loss:\n",
    "    best_eval_loss = eval_loss\n",
    "    print(\"-\"*20)\n",
    "    print(f\"Best Eval loss{best_eval_loss}\")\n",
    "    torch.save(net.state_dict(), \"/content/model.pth\")\n",
    "    print(\"Model Saved Successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
